{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#distance square\n",
    "def dist_sq(a, b):\n",
    "    return np.sum((a-b)**2)\n",
    "#minimum distance square for every point to the centroid\n",
    "def point_sq(data,centroid):\n",
    "    dist=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        dist.append(min(dist_sq(data[i],c) for c in centroid))\n",
    "    return dist\n",
    "        \n",
    "#calculate probability\n",
    "def dist_prob(Dist,l):\n",
    "    return l*Dist/np.sum(Dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def kmeansparallel(data, k, l, d):\n",
    "    #step 1: sample a point uniformly at random from X\n",
    "    index=int(np.random.choice(data.shape[0],1))\n",
    "    centroid=np.array(data[index])\n",
    "    data_copy=data.copy()\n",
    "    data_copy=np.delete(data_copy,index,axis=0)\n",
    "    \n",
    "    #step 2: calculate the cost and number of iterations(log(cost))\n",
    "    cost=np.sum(point_sq(data_copy,centroid))\n",
    "    iteration=math.ceil(np.log(cost))\n",
    "    \n",
    "    #step 3\n",
    "    for number in range(iteration):\n",
    "        #calculate phi_X(C)\n",
    "        distance=point_sq(data_copy,centroid)\n",
    "        #calculate the probability\n",
    "        prob=dist_prob(distance,l).tolist()\n",
    "        for n in range(data_copy.shape[0]):\n",
    "            #if the probability is greater than the random uniform\n",
    "            if prob[n]>np.random.uniform():\n",
    "                #add the point to C\n",
    "                centroid=np.vstack([centroid,np.array(data_copy[n])])\n",
    "                #delete that point from the copy\n",
    "                data_copy=np.delete(data_copy,index,axis=0)\n",
    "    \n",
    "    #step 4: assign the weights\n",
    "    weight_size=centroid.shape[0]\n",
    "    weight=np.zeros(weight_size)\n",
    "    for i in range(data_copy.shape[0]):\n",
    "        index_w=np.argmin(list(dist_sq(data_copy[i],c) for c in centroid))\n",
    "        weight[index_w]=weight[index_w]+1\n",
    "    \n",
    "    #step 5: recluster the weighted points in C into k clusters\n",
    "    #reinitialize k centroids\n",
    "    new_centroids=np.zeros([k,d])\n",
    "    for cluster in range(k):\n",
    "        #according to the weights from step 4, calculate the probability that a point is sampled from C\n",
    "        prob_w=list(weight/sum(weight))\n",
    "        #sample a new centroid\n",
    "        new_index=np.random.choice(centroid.shape[0],1,prob_w)\n",
    "        #store the new centroid\n",
    "        new_centroids[cluster]=centroid[new_index]\n",
    "        #delete the new centroid from the centroid\n",
    "        centroid=np.delete(centroid,new_index,axis=0)\n",
    "        #delete the correponding weight\n",
    "        weight=np.delete(weight,new_index,axis=0)\n",
    "    return new_centroids\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with the initialization of the centroids from the function kmeansparallel\n",
    "#plug in the original data(dataSet), initializtions(initial) and the dimension of the data(d)\n",
    "def kmeans(dataSet, initial, d):\n",
    "    centroids=initial\n",
    "    k=centroids.shape[0]\n",
    "    # Initialize book keeping vars.\n",
    "    iterations = 0\n",
    "    oldCentroids = np.zeros(initial.shape)\n",
    "    \n",
    "    # Run the main k-means algorithm\n",
    "    while not shouldStop(oldCentroids, centroids, iterations):\n",
    "        # Save old centroids for convergence test. Book keeping.\n",
    "        oldCentroids = centroids\n",
    "        iterations += 1\n",
    "        \n",
    "        # Assign labels to each datapoint based on centroids\n",
    "        l= getLabels(dataSet, centroids)\n",
    "        \n",
    "        # Assign centroids based on datapoint labels\n",
    "        centroids = getCentroids(dataSet, l, k, d)\n",
    "        \n",
    "    # We can get the labels too by calling getLabels(dataSet, centroids)\n",
    "    return centroids, np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: Should Stop\n",
    "# -------------\n",
    "# Returns True or False if k-means is done. K-means terminates either\n",
    "# because it has run a maximum number of iterations OR the centroids\n",
    "# stop changing.\n",
    "def shouldStop(oldCentroids, centroids, iterations):\n",
    "    if iterations > 50: return True\n",
    "    return oldCentroids.all == centroids.all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: Get Labels\n",
    "# -------------\n",
    "# Returns a label for each piece of data in the dataset. \n",
    "def getLabels(dataSet, centroids):\n",
    "    # For each element in the dataset, chose the closest centroid. \n",
    "    # Make that centroid the element's label.\n",
    "    l=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        #arg min as the label\n",
    "        l.append(np.argmin(list(dist_sq(data[i],c) for c in centroids)))\n",
    "    return l\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: Get Centroids\n",
    "# -------------\n",
    "# Returns k random centroids, each of dimension n.\n",
    "def getCentroids(dataSet, labels, k, d):\n",
    "    # Each centroid is the arithmetic mean of the points that\n",
    "    # have that centroid's label. Important: If a centroid is empty (no points have\n",
    "    # that centroid's label) you should randomly re-initialize it.\n",
    "    data_new = DataFrame(dataSet.copy())\n",
    "    data_new['Labels'] = labels\n",
    "    data_new = np.array(data_new.groupby(['Labels']).mean().iloc[:,:2])\n",
    "    # if a centroid is empty, reinitialize it \n",
    "    if len(np.unique(labels))<k:\n",
    "        diff=k-len(np.unique(labels))\n",
    "        data_new=np.vstack([data_new,np.random.random([diff,d])])    \n",
    "    return data_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test \n",
    "data=np.array(DataFrame([np.random.random(10000),np.random.random(10000)]).transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48508338,  0.27528881],\n",
       "       [ 0.42037508,  0.69372252],\n",
       "       [ 0.97007772,  0.50123077],\n",
       "       [ 0.07155155,  0.64513388],\n",
       "       [ 0.58442523,  0.54404473],\n",
       "       [ 0.66033139,  0.04235092]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial=kmeansparallel(data, 6, 8, 2)\n",
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.22001227,  0.18971911],\n",
       "        [ 0.49544877,  0.84825679],\n",
       "        [ 0.84327346,  0.72062453],\n",
       "        [ 0.14846873,  0.7312323 ],\n",
       "        [ 0.47611926,  0.46393542],\n",
       "        [ 0.77800061,  0.20070341]]), array([0, 5, 1, ..., 5, 1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans(data,initial,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
