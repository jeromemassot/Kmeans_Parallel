{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#distance square\n",
    "def dist_sq(a, b):\n",
    "    return np.sum((a-b)**2)\n",
    "#minimum distance square for every point to the centroid\n",
    "def point_sq(data,centroid):\n",
    "    dist=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        dist.append(min(dist_sq(data[i],c) for c in centroid))\n",
    "    return dist\n",
    "        \n",
    "#calculate probability\n",
    "def dist_prob(Dist):\n",
    "    return Dist/np.sum(Dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def kmeansplusplus(data, k, d):\n",
    "    #make a copy of the data\n",
    "    data_copy=data.copy()\n",
    "    #step 1: sample a point uniformly at random from x\n",
    "    index=int(np.random.choice(data_copy.shape[0],1))\n",
    "    centroid=data_copy[index]\n",
    "    #once the centroid is determined, delete it from the copy \n",
    "    data_copy=np.delete(data_copy,index,axis=0)\n",
    "    #step 2: while c<k, sample x from X with probability d^2/phi_x(C)\n",
    "    for number in range(k-1):\n",
    "        #calculate the square difference for every point in the copy to its nearest center\n",
    "        distance=point_sq(data_copy,centroid)\n",
    "        #calculate the probability\n",
    "        prob=dist_prob(distance).tolist()\n",
    "        #randomly sample another centroid\n",
    "        index=int(np.random.choice(data_copy.shape[0],1,prob))\n",
    "        #add the new centroid\n",
    "        centroid=np.vstack([centroid,data_copy[index]])\n",
    "        #delete the new centroid from the copy\n",
    "        data_copy=np.delete(data_copy,index,axis=0)\n",
    "    return centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with the initialization of the centroids from the function kmeansplusplus\n",
    "#plug in the original data(dataSet), initializtions(initial) and the dimension of the data(d)\n",
    "def kmeans(dataSet, initial, d):\n",
    "    centroids=initial\n",
    "    k=centroids.shape[0]\n",
    "    # Initialize book keeping vars.\n",
    "    iterations = 0\n",
    "    oldCentroids = np.zeros(initial.shape)\n",
    "    \n",
    "    # Run the main k-means algorithm\n",
    "    while not shouldStop(oldCentroids, centroids, iterations):\n",
    "        # Save old centroids for convergence test. Book keeping.\n",
    "        oldCentroids = centroids\n",
    "        iterations += 1\n",
    "        \n",
    "        # Assign labels to each datapoint based on centroids\n",
    "        l= getLabels(dataSet, centroids)\n",
    "        \n",
    "        # Assign centroids based on datapoint labels\n",
    "        centroids = getCentroids(dataSet, l, k, d)\n",
    "        \n",
    "    # We can get the labels too by calling getLabels(dataSet, centroids)\n",
    "    return centroids, np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function: Should Stop\n",
    "# -------------\n",
    "# Returns True or False if k-means is done. K-means terminates either\n",
    "# because it has run a maximum number of iterations OR the centroids\n",
    "# stop changing.\n",
    "def shouldStop(oldCentroids, centroids, iterations):\n",
    "    if iterations > 50: return True\n",
    "    return oldCentroids.all == centroids.all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function: Get Labels\n",
    "# -------------\n",
    "# Returns a label for each piece of data in the dataset. \n",
    "def getLabels(dataSet, centroids):\n",
    "    # For each element in the dataset, chose the closest centroid. \n",
    "    # Make that centroid the element's label.\n",
    "    l=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        #arg min as the label\n",
    "        l.append(np.argmin(list(dist_sq(data[i],c) for c in centroids)))\n",
    "    return l\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function: Get Centroids\n",
    "# -------------\n",
    "# Returns k random centroids, each of dimension n.\n",
    "def getCentroids(dataSet, labels, k, d):\n",
    "    # Each centroid is the arithmetic mean of the points that\n",
    "    # have that centroid's label. Important: If a centroid is empty (no points have\n",
    "    # that centroid's label) you should randomly re-initialize it.\n",
    "    data_new = DataFrame(dataSet.copy())\n",
    "    data_new['Labels'] = labels\n",
    "    data_new = np.array(data_new.groupby(['Labels']).mean().iloc[:,:2])\n",
    "    # if a centroid is empty, reinitialize it \n",
    "    if len(np.unique(labels))<k:\n",
    "        diff=k-len(np.unique(labels))\n",
    "        data_new=np.vstack([data_new,np.random.random([diff,d])])    \n",
    "    return data_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test \n",
    "data=np.array(DataFrame([np.random.random(100),np.random.random(100)]).transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.71918083,  0.86783032],\n",
       "        [ 0.2309956 ,  0.41364373],\n",
       "        [ 0.39628784,  0.87422448],\n",
       "        [ 0.88068577,  0.45512549],\n",
       "        [ 0.10535794,  0.11895624],\n",
       "        [ 0.67916171,  0.18225129],\n",
       "        [ 0.54517364,  0.59593828],\n",
       "        [ 0.10850523,  0.81978801]]),\n",
       " array([6, 6, 4, 4, 1, 2, 6, 2, 1, 2, 7, 1, 1, 0, 5, 5, 7, 7, 6, 6, 2, 0, 1,\n",
       "        3, 7, 3, 5, 0, 6, 5, 0, 5, 2, 5, 0, 1, 2, 6, 5, 4, 3, 1, 1, 2, 3, 2,\n",
       "        5, 2, 1, 1, 1, 7, 7, 5, 7, 5, 6, 5, 6, 4, 0, 1, 2, 0, 1, 4, 3, 6, 2,\n",
       "        1, 6, 6, 5, 7, 7, 1, 5, 4, 0, 1, 2, 0, 3, 5, 7, 7, 6, 1, 4, 6, 5, 3,\n",
       "        4, 0, 2, 5, 4, 1, 7, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial= kmeansplusplus(data,8,2)\n",
    "kmeans(data, initial,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
